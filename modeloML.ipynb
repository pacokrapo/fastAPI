{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Windows\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "MoviesDataset = pd.read_csv(\"movies_dataset_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "MoviesOverviews = []\n",
    "MoviesTitle = []\n",
    "\n",
    "for i in range(len(MoviesDataset)):\n",
    "    MoviesOverviews.append(MoviesDataset[\"overview\"][i])\n",
    "    MoviesTitle.append(MoviesDataset[\"title\"][i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "for i in range(len(MoviesOverviews)):\n",
    "    if type(MoviesOverviews[i]) == str: \n",
    "        MoviesOverviews[i] = word_tokenize(MoviesOverviews[i])\n",
    "    else:\n",
    "        MoviesOverviews[i] = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "MoviesOverviews2 = [[] for _ in range(len(MoviesOverviews))]\n",
    "\n",
    "for i in range(len(MoviesOverviews)):\n",
    "    for word in MoviesOverviews[i]:\n",
    "        for letter in word:\n",
    "            if letter in string.punctuation:\n",
    "                word=word.replace(letter,\"\")\n",
    "        MoviesOverviews2[i].append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "MoviesOverviews3 = [[] for _ in range(len(MoviesOverviews))]\n",
    "\n",
    "for i in range(len(MoviesOverviews2)):\n",
    "    for word in MoviesOverviews2[i]:\n",
    "        if word != \"\":\n",
    "            MoviesOverviews3[i].append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "MoviesOverviews4 = [[] for _ in range(len(MoviesOverviews))]\n",
    "\n",
    "for i in range(len(MoviesOverviews3)):\n",
    "    for word in MoviesOverviews3[i]:\n",
    "        word = word.lower()\n",
    "        MoviesOverviews4[i].append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "MoviesOverviews5 = [[] for _ in range(len(MoviesOverviews))]\n",
    "\n",
    "for i in range(len(MoviesOverviews4)):\n",
    "    for word in MoviesOverviews4[i]:\n",
    "        if len(word)>=3:\n",
    "            MoviesOverviews5[i].append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Windows\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "a=set(stopwords.words('english'))\n",
    "\n",
    "MoviesOverviews6 = [[] for _ in range(len(MoviesOverviews))]\n",
    "\n",
    "for i in range(len(MoviesOverviews5)):\n",
    "    MoviesOverviews6[i] = [word for word in MoviesOverviews5[i] if word not in a]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "\n",
    "OverviewsFreq = [[] for _ in range(len(MoviesOverviews))]\n",
    "\n",
    "for i in range(len(MoviesOverviews6)):\n",
    "    OverviewsFreq[i] = FreqDist(MoviesOverviews6[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'max': 2, 'family': 1, 'wedding': 1, 'reignites': 1, 'ancient': 1, 'feud': 1, 'nextdoor': 1, 'neighbors': 1, 'fishing': 1, 'buddies': 1, ...})"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OverviewsFreq[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "generador_elementos = (elemento for elemento in MoviesOverviews6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "diccionario = corpora.Dictionary(generador_elementos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "ListaCorpus = []\n",
    "\n",
    "for i in range(len(MoviesOverviews6)):\n",
    "    ListaCorpus.append(diccionario.doc2bow(MoviesOverviews6[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = models.TfidfModel(ListaCorpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tfidf = tfidf[ListaCorpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = similarities.MatrixSimilarity(corpus_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Windows\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\Windows\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "VectoresPromedio = []\n",
    "\n",
    "for i in range(len(corpus_tfidf)):\n",
    "    VectoresPromedio = np.mean(corpus_tfidf[i], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.1379029072983219),\n",
       " (1, 0.4018032585102472),\n",
       " (2, 0.14545949526549312),\n",
       " (3, 0.11857829332504596),\n",
       " (4, 0.09839819088364156),\n",
       " (5, 0.5067592862189615),\n",
       " (6, 0.12034813175227164),\n",
       " (7, 0.13113056668754908),\n",
       " (8, 0.12881258244052007),\n",
       " (9, 0.09621653861189555),\n",
       " (10, 0.12950015408982152),\n",
       " (11, 0.09433753012496303),\n",
       " (12, 0.09283613826239343),\n",
       " (13, 0.09993731495989275),\n",
       " (14, 0.22065119837935337),\n",
       " (15, 0.0777853533245957),\n",
       " (16, 0.11297850849011623),\n",
       " (17, 0.1241073369346856),\n",
       " (18, 0.09587307193268724),\n",
       " (19, 0.08233560893021072),\n",
       " (20, 0.1313194133587423),\n",
       " (21, 0.09193143802244946),\n",
       " (22, 0.10509854574389886),\n",
       " (23, 0.10721270222507849),\n",
       " (24, 0.1256642920280765),\n",
       " (25, 0.14734102602266172),\n",
       " (26, 0.4810540249503552)]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_tfidf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[23489.]])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VectoresPromedio[0].reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = []\n",
    "for elemento in VectoresPromedio:\n",
    "    similitud = cosine_similarity(elemento.reshape(-1,1), VectoresPromedio[0].reshape(-1,1))\n",
    "    resultados.append((elemento, similitud))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_ordenados = sorted(resultados, key=lambda x: x[1], reverse=True)\n",
    "coincidencias = resultados_ordenados[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(23489.0, array([[1.]])), (0.34790062649354103, array([[1.]]))]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coincidencias"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
